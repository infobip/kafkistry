package com.infobip.kafkistry.service.topic.wizard

import com.fasterxml.jackson.databind.ObjectMapper
import com.fasterxml.jackson.module.kotlin.KotlinModule
import org.apache.kafka.common.config.TopicConfig.*
import com.infobip.kafkistry.kafkastate.KafkaClusterState
import com.infobip.kafkistry.kafkastate.StateData
import com.infobip.kafkistry.kafkastate.StateType
import com.infobip.kafkistry.model.*
import com.infobip.kafkistry.service.TopicWizardException
import com.infobip.kafkistry.service.generator.OverridesMinimizer
import com.infobip.kafkistry.service.resources.RequiredResourcesInspector
import com.infobip.kafkistry.service.resources.TopicResourceRequiredUsages
import com.infobip.kafkistry.service.topic.validation.NamingValidator
import com.infobip.kafkistry.model.ClusterRef
import com.infobip.kafkistry.model.KafkaClusterIdentifier
import com.infobip.kafkistry.model.Tag
import org.springframework.boot.context.properties.ConfigurationProperties
import org.springframework.boot.context.properties.NestedConfigurationProperty
import org.springframework.context.annotation.Configuration
import org.springframework.stereotype.Component
import java.util.*
import kotlin.math.min

@Configuration
@ConfigurationProperties("app.topic-wizard")
class TopicWizardProperties {

    var defaultPartitionCount = 1
    var partitionThresholds = "{}"

    @NestedConfigurationProperty
    var segmentSize = SegmentSizeProperties()

    class SegmentSizeProperties {
        var toRetentionRatioSmall = 0.5
        var retentionSizeBigThreshold = 100L shl 20
        var toRetentionRatioBig = 0.1
    }
}

@Component
class TopicWizardConfigGenerator(
        topicNameGenerator: Optional<TopicNameGenerator>,
        private val minimizer: OverridesMinimizer,
        private val namingValidator: NamingValidator,
        private val requiredResourcesInspector: RequiredResourcesInspector,
        private val properties: TopicWizardProperties,
) {

    private val nameGenerator: TopicNameGenerator = topicNameGenerator.orElse(DefaultTopicNameGenerator)
    private val partitionCountAssignor = PartitionCountAssignor(properties.defaultPartitionCount, properties.partitionThresholds)

    fun generateTopicDescription(
            wizardAnswers: TopicCreationWizardAnswers,
            allClusters: Map<ClusterRef, StateData<KafkaClusterState>>
    ): TopicDescription {
        val topicPresence = wizardAnswers.presence
        val clusterConfigs = allClusters
                .filterKeys { topicPresence.needToBeOnCluster(it) }
                .mapValues { generateTopicConfigurationForCluster(wizardAnswers, it.key, it.value) }
        val topicDescription = TopicDescription(
                name = generateName(wizardAnswers.topicNameMetadata),
                properties = ignoredProperties(),
                owner = wizardAnswers.teamName,
                producer = wizardAnswers.producerServiceName,
                description = generateDescription(wizardAnswers),
                resourceRequirements = wizardAnswers.resourceRequirements,
                presence = topicPresence,
                config = emptyMap(),
                perClusterProperties = clusterConfigs.map { it.key.identifier to it.value.properties }.toMap(),
                perClusterConfigOverrides = clusterConfigs.map { it.key.identifier to it.value.config }.toMap(),
                perTagProperties = emptyMap(),
                perTagConfigOverrides = emptyMap(),
        )
        return minimizer.minimizeOverrides(topicDescription, clusterConfigs.keys.toList())
    }

    /**
     * This value here will be completely ignored because we generate TopicProperties per each cluster
     * which will be moved "up/global" to replace this value.
     *
     * But something needs to be specified here because field TopicDescription.properties is non-nullable.
     */
    internal fun ignoredProperties() = TopicProperties(1, 1)

    fun generateName(topicNameMetadata: TopicNameMetadata): String {
        return nameGenerator.generateTopicName(topicNameMetadata).also {
            namingValidator.validateTopicName(it)
        }
    }

    private fun generateDescription(wizardAnswers: TopicCreationWizardAnswers): String {
        return wizardAnswers.purpose + "\n\n" + "Topic generated by Kafkistry wizard"
    }

    private fun generateTopicConfigurationForCluster(
        wizardAnswers: TopicCreationWizardAnswers,
        clusterRef: ClusterRef,
        clusterState: StateData<KafkaClusterState>
    ): GeneratedConfig {
        val partitionCount = determinePartitionCount(wizardAnswers.resourceRequirements, clusterRef)
        val (replicationFactor, minInSyncReplicas) = determineTopicAvailabilityGuarantees(
            wizardAnswers, clusterRef.identifier, clusterState
        )
        val topicProperties = TopicProperties(partitionCount, replicationFactor)
        val retentionMs = wizardAnswers.resourceRequirements.retention.toMillis()
        val resourceUsages = requiredResourcesInspector.inspectTopicResources(
                topicProperties = topicProperties,
                resourceRequirements = wizardAnswers.resourceRequirements,
                clusterRef = clusterRef,
                clusterInfo = clusterState.valueOrNull()?.clusterInfo
        )
        val retentionBytes = resourceUsages.diskUsagePerPartitionReplica
        val segmentBytes = determineSegmentBytes(retentionBytes)
        return GeneratedConfig(
                properties = topicProperties,
                config = mapOf(
                        RETENTION_BYTES_CONFIG to "$retentionBytes",
                        RETENTION_MS_CONFIG to "$retentionMs",
                        MIN_IN_SYNC_REPLICAS_CONFIG to "$minInSyncReplicas",
                        SEGMENT_BYTES_CONFIG to "$segmentBytes",
                ),
                resourceRequiredUsages = resourceUsages,
                comments = listOf()
        )
    }

   fun determineSegmentBytes(retentionBytes: Long): Long {
        return with(properties.segmentSize) {
            val thresholdSegmentBytes = retentionSizeBigThreshold.times(toRetentionRatioSmall).toLong()
            when (retentionBytes < retentionSizeBigThreshold) {
                true -> retentionBytes.times(toRetentionRatioSmall).toLong()
                false -> retentionBytes.times(toRetentionRatioBig).toLong().coerceAtLeast(thresholdSegmentBytes)
            }
        }
    }

    fun determinePartitionCount(
            resourceRequirements: ResourceRequirements,
            clusterRef: ClusterRef
    ): Int {
        val messagesRate = resourceRequirements.messagesRate(clusterRef)
        if (messagesRate.amount <= 0) {
            throw TopicWizardException("messages rate (Throughput) must be > 0. Cluster: ${clusterRef.identifier}, Value: $messagesRate")
        }
        return partitionCountAssignor.assignPartitionCount(messagesRate.ratePerSec(), clusterRef)
    }

    private fun determineTopicAvailabilityGuarantees(
        wizardAnswers: TopicCreationWizardAnswers,
        clusterIdentifier: KafkaClusterIdentifier,
        clusterState: StateData<KafkaClusterState>
    ): TopicAvailabilityGuarantees {
        val (wantedReplicationFactor, tolerateDataLoss) = when (wizardAnswers.highAvailability) {
            HighAvailability.NONE -> return TopicAvailabilityGuarantees(1, 1)
            HighAvailability.BASIC -> 2 to true
            HighAvailability.STRONG_AVAILABILITY -> 3 to true
            HighAvailability.STRONG_DURABILITY -> 3 to false
        }
        val numberBrokerNodes = when (clusterState.stateType) {
            StateType.VISIBLE -> clusterState.value().clusterInfo.nodeIds.size
            StateType.DISABLED -> wantedReplicationFactor
            else -> throw TopicWizardException(
                    "Can't suggest replication factor for cluster '$clusterIdentifier' because it's state is ${clusterState.stateType}"
            )
        }
        val replicationFactor = min(wantedReplicationFactor, numberBrokerNodes)
        return if (tolerateDataLoss) {
            TopicAvailabilityGuarantees(replicationFactor, 1)
        } else {
            TopicAvailabilityGuarantees(replicationFactor, minInSyncReplicas = replicationFactor - 1)
        }
    }

    private data class GeneratedConfig(
        val properties: TopicProperties,
        val config: TopicConfigMap,
        val resourceRequiredUsages: TopicResourceRequiredUsages,
        val comments: List<String>
    )

}

private class PartitionCountAssignor(
    val defaultPartitionCount: Int,
    wizardPartitionThresholdsJson: String
) {

    private val thresholdsConfig: ThresholdsConfig = ObjectMapper()
            .registerModule(KotlinModule())
            .readValue(wizardPartitionThresholdsJson, ThresholdsConfig::class.java)

    fun assignPartitionCount(msgPerSec: Double, clusterRef: ClusterRef): Int {
        val thresholds = thresholdsConfig.overrides[clusterRef.identifier]
            ?: clusterRef.tags.mapNotNull { thresholdsConfig.tagOverrides[it] }.firstOrNull()
            ?: thresholdsConfig.default
        return thresholds.floorEntry(msgPerSec)?.value ?: defaultPartitionCount
    }

}

private data class ThresholdsConfig(
    val default: TreeMap<Double, Int> = TreeMap(),
    val overrides: Map<KafkaClusterIdentifier, TreeMap<Double, Int>> = emptyMap(),
    val tagOverrides: Map<Tag, TreeMap<Double, Int>> = emptyMap(),
)

private data class TopicAvailabilityGuarantees(val replicationFactor: Int, val minInSyncReplicas: Int)